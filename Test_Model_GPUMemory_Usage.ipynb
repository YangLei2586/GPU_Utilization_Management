{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from numba import cuda\n",
    "\n",
    "def test_gpu_usage(self):\n",
    "    with open(\"test/data/model/training\",\"rb\") as f:\n",
    "        X,Y,L,D = pickle.load(f)\n",
    "    \n",
    "    Xs, Ys, Ls, Ds = split_data(X,Y,L,D,splits=[0.8,0,1,0.1], stratify_by=Y, seed=123)\n",
    "    \n",
    "    label_model = LabelModel(k=2,seed=123)\n",
    "    label_model.train_model(Ls[0],Y_dev=Ys[1], n_epochs=500, log_train_every=25)\n",
    "    Y_train_ps = label_model.predict_proba(Ls[0])\n",
    "    \n",
    "    # creating a really large end model to use lots of memory\n",
    "    end_model=EndModel([1000, 100000, 2], seed=123,device=\"cuda\")\n",
    "    \n",
    "    # getting initial GPU storage use \n",
    "    initial_gpu_mem = GPUtil.getGPUs()[0].memoryUsed\n",
    "    \n",
    "    # Training model\n",
    "    end_model.train_model(\n",
    "        (Xs[0],Y_train_ps),\n",
    "        valid_data=(Xs[1],Ys[1],\n",
    "        l2=0.1,\n",
    "        batch_size=256,\n",
    "        n_epochs=3,\n",
    "        log_train_every=1,\n",
    "        validation_metric=\"f1\",)\n",
    "        \n",
    "    # Final GPU memory use \n",
    "    final_gpu_mem = GPUtil.getGPUs()[0].memoryUsed\n",
    "        \n",
    "    # On a Titan X, this model uses about 3 GB of memory\n",
    "    gpu_mem_difference = final_gpu_mem - initial_gpu_mem\n",
    "        \n",
    "    self.assertGreater(gpu_mem_difference,1000)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
